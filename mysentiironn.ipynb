{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sentistrength import PySentiStr\n",
        "import pandas as pd\n",
        "import csv\n",
        "from itertools import zip_longest\n",
        "from difflib import SequenceMatcher\n",
        "from hunspell import Hunspell\n",
        "import os\n",
        "\n",
        "\n",
        "mode='bin'\n",
        "def clearfiles():\n",
        "\tdata = pd.read_csv(\"./dataset/dirtyreviews.csv\")\n",
        "\n",
        "\tdata=data.drop('topic',1)\n",
        "\tdata=data.drop('title',1)\n",
        "\n",
        "\tdata=data.dropna()\n",
        "\tdata=data.drop_duplicates(subset=['comment'], keep='first')\n",
        "\ttemp=[]\n",
        "\ttemp=data['stars'].values.tolist()\n",
        "\tname='reviewstars'+mode\n",
        "\tif mode=='bin':\n",
        "\t\tfor i in range(0,len(data['stars'])):\n",
        "\t\t\t\n",
        "\t\t\tif int(temp[i])<=3:\n",
        "\t\t\t\ttemp[i]=0;\n",
        "\t\t\telse:\n",
        "\t\t\t\ttemp[i]=1;\t\n",
        "\n",
        "\telse:\n",
        "\t\tfor i in range(0,len(data['stars'])):\n",
        "\t\t\t\n",
        "\t\t\tif int(temp[i])<=2:\n",
        "\t\t\t\ttemp[i]=-1;\n",
        "\t\t\telif int(temp[i])=3:\n",
        "\t\t\t\ttemp[i]=0;\n",
        "\t\t\telse:\t\t\n",
        "\t\t\t\ttemp[i]=1;\n",
        "\tdata['stars']=temp\n",
        "\n",
        "\tcols=data.columns.tolist()\n",
        "\tcols = cols[-1:] + cols[:-1]\n",
        "\tdata=data[cols]\n",
        "\n",
        "\tdata.to_csv('./dataset/'+name+'.csv',header=['reviews','sentiment'],index=False,encoding = \"utf-8\")\n",
        "\n",
        "def splitfiles(mode):\n",
        "\tif mode=='bin':\n",
        "\t\tdata = pd.read_csv(\"./dataset/reviewstarsbin.csv\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\t\tdata['sentiment'].to_csv('starsbin.csv',header=['sentiment'],index=False)\n",
        "\n",
        "\t\tdata['reviews'].to_csv('reviews.csv',header=['reviews'],index=False,encoding = \"utf-8\")\n",
        "\telse:\n",
        "\t\tdata = pd.read_csv(\"./dataset/reviewstarsnonbin.csv\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\t\tdata['sentiment'].to_csv('stars.csv',header=['sentiment'],index=False)\n",
        "\n",
        "\t\tdata['reviews'].to_csv('reviews.csv',header=['reviews'],index=False,encoding = \"utf-8\")\t\t\n",
        "\n",
        "\n",
        "def clean_accent(text):\n",
        "\n",
        "    t = text\n",
        "\n",
        "    # el\n",
        "    t = t.replace('\u0386', '\u0391')\n",
        "    t = t.replace('\u0388', '\u0395')\n",
        "    t = t.replace('\u038a', '\u0399')\n",
        "    t = t.replace('\u0389', '\u0397')\n",
        "    t = t.replace('\u038e', '\u03a5')\n",
        "    t = t.replace('\u038c', '\u039f')\n",
        "    t = t.replace('\u038f', '\u03a9')\n",
        "    t = t.replace('\u03ac', '\u03b1')\n",
        "    t = t.replace('\u03ad', '\u03b5')\n",
        "    t = t.replace('\u03af', '\u03b9')\n",
        "    t = t.replace('\u03ae', '\u03b7')\n",
        "    t = t.replace('\u03cd', '\u03c5')\n",
        "    t = t.replace('\u03cc', '\u03bf')\n",
        "    t = t.replace('\u03ce', '\u03c9')\n",
        "    t = t.replace('\u03c2', '\u03c3')\n",
        "    t = t.replace('\u2661', '')\n",
        "    t = t.replace('\u2606', '')\n",
        "    t = t.replace('*', '')\n",
        "  \n",
        "\n",
        "   \n",
        "    return t\t\n",
        "\n",
        "def zerolistmaker(n):\n",
        "    listofzeros = [0] * n\n",
        "    return listofzeros    \n",
        "\n",
        "\n",
        "#Hunspell check\n",
        "h = Hunspell('el_GR')\n",
        "#if not a new .csv is downloaded and in folder\n",
        "#clear it and fix it\n",
        "if not(os.path.isfile('./dataset/reviewstarsbin.csv')):\n",
        "\tclearfiles(mode)\n",
        "\tprint('Cleared')\n",
        "#run split to have both reviews and stars .csv\n",
        "splitfiles(mode)\n",
        "if mode=='nonbin':\n",
        "\t#File with reviews\n",
        "\tfile_name=\"reviews.csv\"\n",
        "\tstars_name=\"stars.csv\"\n",
        "else:\n",
        "\tfile_name=\"reviews.csv\"\n",
        "\tstars_name=\"starsbin.csv\"\n",
        "\n",
        "with open(file_name, newline='\\n',encoding='utf-8') as f:\n",
        "    df = csv.reader(f)\n",
        "    df = list(df)\n",
        "    df = list(filter(None, df)) #list of reviews with no duplicates\n",
        "with open(stars_name, newline='\\n') as g:\n",
        "    stt = []\n",
        "    for row in csv.reader(g, delimiter=';'):\n",
        "\n",
        "        stt.append(row[0]) # stars array\n",
        "\n",
        "\t\n",
        "\n",
        "#pharm lexicon\n",
        "with open('finallexformysenti\\\\EmotionLookupTable.txt', 'r', encoding='utf-8')  as file:    terms_list = file.read().splitlines()\n",
        "\n",
        "word=[] #2 arrays for word and score\n",
        "score=[]\n",
        "\n",
        "for t in terms_list:\n",
        "\tt = t.split(\"\t\")\n",
        "\tword.append(t[0])\n",
        "\tscore.append(t[1])\n",
        "\n",
        "for i in range(0,len(score)):\n",
        "\tscore[i]=int(score[i]) #make int from string\n",
        "\n",
        "for i in range(0,len(word)):\n",
        "\tword[i]=clean_accent(word[i].lower()) #clean accent of word\n",
        "\n",
        "\n",
        "\n",
        "######emoticontable same as pharm######\n",
        "with open('finallexformysenti\\\\EmoticonLookupTable.txt', 'r') as file:    emotic_list = file.read().splitlines()\n",
        "emot=[]\n",
        "scorem=[]\n",
        "for te in emotic_list:\t\n",
        "\tte = te.split(\"\t\")\n",
        "\temot.append(te[0])\n",
        "\tscorem.append(te[1])\n",
        "for i in range(0,len(scorem)):\t\n",
        "\tscorem[i]=int(scorem[i])\t\n",
        "\n",
        "\n",
        "#boosterwords same as before\n",
        "with open('finallexformysenti\\\\BoosterWordList.txt', 'r', encoding='utf-8') as file:    terms_listbo = file.read().splitlines()\n",
        "\n",
        "boost=[]\n",
        "scorebo=[]\n",
        "\n",
        "for tb in terms_listbo:\n",
        "\ttb = tb.split(\"\t\")\n",
        "\tboost.append(tb[0])\n",
        "\tscorebo.append(tb[1])\n",
        "for i in range(0,len(scorebo)):\n",
        "\tscorebo[i]=int(scorebo[i])\n",
        "for i in range(0,len(boost)):\n",
        "\tboost[i]=clean_accent(boost[i].lower())\n",
        "\n",
        "#negwords\n",
        "with open('finallexformysenti\\\\NegatingWordList.txt', 'r', encoding='utf-8') as file:    terms_listneg = file.read().splitlines()\n",
        "neg=[]\n",
        "for tn in terms_listneg:\n",
        "\ttn = tn.split(\"\t\")\n",
        "\tneg.append(tn[0])\n",
        "for i in range(0,len(neg)):\n",
        "\tneg[i]=clean_accent(neg[i].lower())\n",
        "\n",
        "\n",
        "#Constants declarations\n",
        "suffix_prune_el=3 #prune in words\n",
        "string_min_score = 0.76 #matching score\n",
        "kek=0 #number of words that were checked\n",
        "lel=0 #sum of words\n",
        "\n",
        "\n",
        "scorerev=[0] #score per review\n",
        "mins=[-1] #min score per review\n",
        "maxs=[1] #max score per review\n",
        "i=0 #an i\n",
        "stikshh=['.',' ','-','_','+','w','\u00b0','?',';','!',':','(',')'] #unwanted chars\n",
        "stiksh=['.',' ','-','_','+','w','\u00b0','?',';','!','0','1','2','3','4','5','6','7','8','9'] #unwanted chars that may repeat\n",
        "summinmax=[0]\n",
        "with open('dataset\\\\finalgreekmysenti'+mode+'.csv', 'w',newline='',encoding='utf8') as f: #results csv\n",
        "\twriter = csv.writer(f, delimiter=',')\n",
        "\twriter.writerow(('review','mysentiment','min','max','sentiment')) #row titles\n",
        "\tfor review in df: #every review\n",
        "\n",
        "\t\treview = [x.replace('\\n', '') for x in review] #bgazw to /n pou ebale to opencsv\n",
        "\t\t\n",
        "\t\tflag=False #kathe review arxikopoiw false. An ginei true meta h epomenh leksh pou brisketai den metrate\n",
        "\t\t\t\n",
        "\t\trvwords=review[0].split(\" \") #kathe leksh pou exei to review\n",
        "\n",
        "\t\trvwords=list(rvwords) #list\n",
        "\n",
        "\t\tfor words in rvwords:\t\n",
        "\t\t\tsr=0 #sr start every word\n",
        "\t\t\tlel=lel+1 #count words\n",
        "\t\t\twords=clean_accent(words) #clean accent of word\n",
        "\n",
        "\t\t\t#emoticon first before any stiksh split so not to lose \t\n",
        "\t\t\tif words in emot:\t\n",
        "\t\t\t\tkek=kek+1 #word find counter\n",
        "\t\t\t\tsr=scorem[emot.index(words)]\n",
        "\t\t\t\tscorerev[i]=scorerev[i]+sr #if found adds score to review score\n",
        "\t\t\telse:\t\t\n",
        "\n",
        "\t\t\t#punctuation if no emoticon found\t\n",
        "\t\t\t\t\n",
        "\t\t\t\ta=['']\t#starts a dummy array to see if there is a !\n",
        "\t\t\t\tif '!' in words:\n",
        "\t\t\t\t\ta=words.split('!')\t#word is spliting from !. After this algorithm\n",
        "\t\t\t\t\t\t\t\t\t\t#cant find ! and word remains the same without ! \n",
        "\t\t\t\t\t\t\t\t\t\t#so I can add word's score with ! boost\n",
        "\t\t\t\t\t\t        \n",
        "\t\t\t\tfor p in range(0,len(words)):\n",
        "\t\t\t\t\tif \twords[p:p+1] in stikshh: #replacing every weird char with '' so word can be clear\n",
        "\t\t\t\t\t\twords=words.replace(words[p:p+1],'')\n",
        "\t\t\t\t\t\twords=words.replace('.','')\n",
        "\t\t\t\t\t\t\n",
        "\t\t\t#threepeat letters checker and hunspell sugestion after removing them.\n",
        "\t\t\t#Tested and gives good suggestions. Check also that word is not a punctuation or number\t\t\t\n",
        "\t\t\t\tk=['']\t\n",
        "\t\t\t\tfor p in range(3,len(words)):\t\n",
        "\t\t\t\n",
        "\t\t\t\t\tif (words[p-1:p]==words[p-2:p-1]==words[p-3:p-2] and (words[p-1:p] not in stiksh)):\n",
        "\t\t\t\t\t\twords=''.join(sorted(set(words), key=words.index))\n",
        "\t\t\t\t\t\t#print(words)\n",
        "\t\t\t\t\t\t\n",
        "\t\t\t\t\t\tk=h.suggest(words)\n",
        "\t\t\t\t\t\tif k!=():\t\n",
        "\t\t\t\t\t\t\twords=k[0]\n",
        "\t\t\t\t\t\tbreak\t\n",
        "\n",
        "\t\t\t\t#Negative word check. If found flag=True and next word emotion skipped\n",
        "\t\t\t\tif words in neg:\n",
        "\t\t\t\t\tkek=kek+1\n",
        "\t\t\t\t\tflag=True\n",
        "\t\t\t\t\t\t\t\t\n",
        "\t\t\t\t#main list check and scoring\t\t\t\t\n",
        "\t\t\t\t#get words that start with the first letter of word that we check\n",
        "\t\t\t\t#saves A LOT of time\n",
        "\t\t\t\tfor wrd in [m for m in word if m.lower().startswith(words[:1])]: \n",
        "\t\t\t\t\tmatch = words.find(wrd[:max(3, len(wrd)-suffix_prune_el)]) #match word with pruning\n",
        "\t\t\t\t\tscorera = SequenceMatcher(None, words, wrd).ratio() #ratio of final matching\n",
        "\t\t\t\t\tif match==0 and scorera>string_min_score: #match and ratio>\n",
        "\t\t\t\t\t\tkek=kek+1 #word counter\n",
        "\t\t\t\t\t\tif flag==True:\n",
        "\t\t\t\t\t\t\tflag=False #if flag=True do it false and stop\n",
        "\t\t\t\t\t\telse:\n",
        "\t\t\t\t\t\t\tsr=score[word.index(wrd)] #found score of word\n",
        "\t\t\t\t\t\t\tif a[0]!='': #If ! found\n",
        "\t\t\t\t\t\t\t\tif sr==-1: #score of word from -1->2\n",
        "\t\t\t\t\t\t\t\t\tsr=2\t\n",
        "\t\t\t\t\t\t\t\telse:\t\n",
        "\t\t\t\t\t\t\t\t\tsr=sr+1 #other score of word +1 \n",
        "\t\t\t\t\t\t\t\n",
        "\t\t\t\t\t\t\tscorerev[i]=scorerev[i]+sr #sum score of review\n",
        "\t\t\t\t#if words in boost add in score\t\t\t\n",
        "\t\t\t\tif words in boost:\n",
        "\t\t\t\t\tkek=kek+1 #word counter\n",
        "\t\t\t\t\tsr=scorebo[boost.index(words)]\n",
        "\t\t\t\t\tscorerev[i]=scorerev[i]+sr\n",
        "\t\t\t#check for max review score\tuntil this word in every case se is the added score\n",
        "\t\t\t#from word\n",
        "\t\t\tif sr>maxs[i]:\n",
        "\t\t\t\tmaxs[i]=sr\n",
        "\t\t\t#check for min review score\tuntil this word\n",
        "\t\t\tif sr<mins[i]:\n",
        "\t\t\t\tmins[i]=sr\t\n",
        "\n",
        "\t\t#add min and max to produce the final score and label\t\n",
        "\t\t#-1 if neg, 0 if neutr, 1 if positive\t\n",
        "\t\tsumminmax[i]=maxs[i]+mins[i]\n",
        "\t\tif summinmax[i]<=0: \n",
        "\t\t\tsumminmax[i]=0\n",
        "\n",
        "\t\t#elif -1 <summinmax[i]<1:\n",
        "\t\t\t\n",
        "\t\t#\tsumminmax[i]=0 \n",
        "\t\telse:\n",
        "\t\t\tsumminmax[i]=1\t\n",
        "\n",
        "\t\ti=i+1 \n",
        "\t\tsumminmax.append(0)\n",
        "\t\tscorerev.append(0)\t\n",
        "\t\tmins.append(-1)\t\n",
        "\t\tmaxs.append(1)\t\n",
        "\n",
        "\tprint('Words found in lexicon: ',kek,' Total words: ',lel)\t#words found,total words\n",
        "\tprint('\\n Ratio: ',kek/lel)\t#ratio found\n",
        "\n",
        "\tt=[df,summinmax,mins,maxs,stt] #exported data\n",
        "\texport_data = zip_longest(*t) #zip and write\n",
        "\twriter.writerows(export_data)\t\t\t\n",
        "\n",
        "#######Prediction accuracy############################################################\n",
        "dataset='./dataset/finalgreekmysenti'+mode+'.csv'\n",
        "\n",
        "df=pd.read_csv(dataset)\n",
        "\n",
        "res=[]\n",
        "sent=[]\n",
        "\n",
        "sent=df['sentiment']\n",
        "res=df['mysentiment']\n",
        "\n",
        "cnt=0\n",
        "for i in range(1,len(res)-1):\n",
        "\tif int(res[i])==int(sent[i]):\n",
        "\t\tcnt=cnt+1\n",
        "print('Correct Predicted: ',cnt,' = ',cnt/len(summinmax)*100,'%')\t"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}